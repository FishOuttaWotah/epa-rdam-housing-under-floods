{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from util_data_exploration import get_tile_images, reconvert_np_to_rasterio_dataset\n",
    "from util_funcs import generate_flood_distribution_in_bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "data/Mflood1_grotekans/MaximaleWaterdiepteNederland_Kaart1.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCPLE_OpenFailedError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32mrasterio\\_base.pyx\u001B[0m in \u001B[0;36mrasterio._base.DatasetBase.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mrasterio\\_shim.pyx\u001B[0m in \u001B[0;36mrasterio._shim.open_dataset\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mrasterio\\_err.pyx\u001B[0m in \u001B[0;36mrasterio._err.exc_wrap_pointer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mCPLE_OpenFailedError\u001B[0m: data/Mflood1_grotekans/MaximaleWaterdiepteNederland_Kaart1.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRasterioIOError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_30924/3920639222.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m     'data/Mflood5_extreemkleinekans/MaximaleWaterdiepteNederland_Kaart5.tif']\n\u001B[0;32m      8\u001B[0m \u001B[1;31m# with rasterio.open(scenario_path) as NL_map:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mflood_maps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mrasterio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mscenario_folders\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mflood_map\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrasterio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscenario_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mwijken\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/wijk_geometries.shp'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_30924/3920639222.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      7\u001B[0m     'data/Mflood5_extreemkleinekans/MaximaleWaterdiepteNederland_Kaart5.tif']\n\u001B[0;32m      8\u001B[0m \u001B[1;31m# with rasterio.open(scenario_path) as NL_map:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mflood_maps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mrasterio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mscenario_folders\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mflood_map\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrasterio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscenario_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mwijken\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/wijk_geometries.shp'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\Users\\fishe\\anaconda3\\envs\\tpm-aabm-2\\lib\\site-packages\\rasterio\\env.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    433\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0menv_ctor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 435\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    436\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    437\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\Users\\fishe\\anaconda3\\envs\\tpm-aabm-2\\lib\\site-packages\\rasterio\\__init__.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m         \u001B[1;31m# None.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 207\u001B[1;33m             \u001B[0ms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDatasetReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdriver\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdriver\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msharing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msharing\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    208\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"r+\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    209\u001B[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001B[1;32mrasterio\\_base.pyx\u001B[0m in \u001B[0;36mrasterio._base.DatasetBase.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mRasterioIOError\u001B[0m: data/Mflood1_grotekans/MaximaleWaterdiepteNederland_Kaart1.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "scenario_path = 'data/Mflood1_grotekans/MaximaleWaterdiepteNederland_Kaart1.tif'\n",
    "scenario_folders = [\n",
    "    'data/Mflood1_grotekans/MaximaleWaterdiepteNederland_Kaart1.tif',\n",
    "    'data/Mflood2_middelgrotekans/MaximaleWaterdiepteNederland_Kaart2.tif',\n",
    "    'data/Mflood3_kleinekans/MaximaleWaterdiepteNederland_Kaart3.tif',\n",
    "    'data/Mflood4_zeerkleinkans/MaximaleWaterdiepteNederland_Kaart4.tif',\n",
    "    'data/Mflood5_extreemkleinekans/MaximaleWaterdiepteNederland_Kaart5.tif']\n",
    "# with rasterio.open(scenario_path) as NL_map:\n",
    "flood_maps = [rasterio.open(path) for path in scenario_folders]\n",
    "flood_map = rasterio.open(scenario_path)\n",
    "wijken = gpd.read_file('data/wijk_geometries.shp')\n",
    "buurten = gpd.read_file('data/Rdam_buurten_shape.shp')\n",
    "rdam_dsm_map = rasterio.open('data/rdam_topo_map.tif')\n",
    "# Mask using shapefile\n",
    "buurt_geometries = buurten.geometry.to_list()\n",
    "df_flood_submaps = pd.read_pickle('data/df_flood_submaps.pkl.gz')\n",
    "wijk_names = pd.read_pickle('data/wijk_names.pkl.gz')\n",
    "rdam_land_bool_map = rasterio.open('data/rdam_topo_bool_map.tif')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge DSM tiles into one image (one-time item, reactivate whenever necessary)\n",
    "Procedure:\n",
    "1. Retrieve all items from directory to be merged with\n",
    "2. Open all items into list\n",
    "3. Use rasterio.merge to save all into TIFF image for future use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## merge dtm tiles into one unified  (create function later)\n",
    "# path = 'data/DSMs/'\n",
    "# dtm_files = [f for f in os.listdir(path) if '.tif' in f.lower()]\n",
    "# # load into list for now\n",
    "# dtm_list = [rasterio.open(f'{path}{name}') for name in dtm_files]\n",
    "#\n",
    "# mosaic, mosaic_trans = rasterio.merge.merge(dtm_list)\n",
    "# f32_inf = 340282346638528859811704183484516925440.00000 # not necessary?\n",
    "# # mosaic[mosaic == f32_inf] = np.nan # ALERT: not necessary!\n",
    "#\n",
    "# fig, ax = plt.subplots()\n",
    "# show(mosaic, transform=mosaic_trans,ax=ax)\n",
    "# # plt.savefig('data/test_map.jpg',dpi=1000)\n",
    "# # Save merged map as TIF image (for further reuse), one-time\n",
    "# with rasterio.open('data/rdam_topo_map.tif',mode='w',count=1,\n",
    "#                    width=mosaic.squeeze().shape[1],\n",
    "#                    height=mosaic.squeeze().shape[0],\n",
    "#                    crs=dtm_list[0].crs,\n",
    "#                    transform=mosaic_trans,\n",
    "#                    dtype=dtm_list[0].dtypes[0]) as dest:\n",
    "#     dest.write(mosaic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting the Topo Map to boolean map for land/water\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## CONVERSION OF TOPO MAP TO LAND/WATER BOOLEAN MAP, SCALED TO SAME FACTOR AS FLOOD MAP\n",
    "# ## get rdam bool of land/water = 1/0 and save\n",
    "# rdam_land_bool_map = rdam_dsm_map.read(1) < 3e38    # where 3e38 ~= numerical infinity\n",
    "# downscale_factor = 5\n",
    "# # np.newaxis creates an extra dummy axis for\n",
    "# test_collapse = get_tile_images(rdam_land_bool_map[:,:,np.newaxis],\n",
    "#                                 width=downscale_factor, height=downscale_factor)\n",
    "#\n",
    "# ## AGGREGATE TO NEW RESOLUTION VIA WATER-BOOL METHOD\n",
    "# # since water/land is simply as 1/0,\n",
    "# test_collapse2 = np.sum(test_collapse,axis=(2,3)).squeeze()\n",
    "# # need to filter out again into binary\n",
    "# test_collapse3 = (test_collapse2 > ((downscale_factor * downscale_factor) //2) + 1).astype(int)\n",
    "#\n",
    "# sanity_check = True\n",
    "# if sanity_check:\n",
    "#     # Sanity check: to see if the delta affects the accuracy of downsampling\n",
    "#     fitting = []\n",
    "#     binary_bound = range(0,25,1)\n",
    "#     for bound in binary_bound:\n",
    "#         fitting.append(np.sum(test_collapse2 > bound))\n",
    "#\n",
    "#     deltas = (fitting-fitting[0])/(test_collapse2.shape[0]*test_collapse2.shape[1])\n",
    "#     plt.scatter(x=binary_bound, y=deltas)\n",
    "#\n",
    "#     \"\"\" The plot below shows x = 'bound limit for accepting the cell as terrain', and y = 'percentage delta of terrain that would increase if the bound increases'.\n",
    "#\n",
    "#     With increasing bound threshold, between 0 <= bound <= 15 the percentage difference is on the order of 0 - 4% (using bound = 0 as a base case). Using the midpoint (25/2 = 12.5) makes for an acceptable bound for aggregation.\n",
    "#     \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # CORRECT AFFINE TRANSFORM AND RECREATE AS DATASET AGAIN\n",
    "# host_map = rdam_dsm_map # original coordinate bounds\n",
    "# # generate new affine transform\n",
    "# test_collapse3_transform = rasterio.transform.from_bounds(\n",
    "#     west=host_map.bounds.left,\n",
    "#     south=host_map.bounds.bottom,\n",
    "#     east=host_map.bounds.right,\n",
    "#     north=host_map.bounds.top,\n",
    "#     width=test_collapse3.shape[1],\n",
    "#     height=test_collapse3.shape[0]\n",
    "# )\n",
    "# # recreate Rasterio Dataset object\n",
    "# test_collapse4 = reconvert_np_to_rasterio_dataset(test_collapse3, transform=test_collapse3_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # save rasterio dataset object\n",
    "# with rasterio.open('data/rdam_topo_bool_map.tif', mode='w', count=1,\n",
    "#                    width=test_collapse3.shape[1],\n",
    "#                    height=test_collapse3.shape[0],\n",
    "#                    crs=rdam_dsm_map.crs,\n",
    "#                    transform=test_collapse3_transform,\n",
    "#                    dtype=test_collapse3.dtype) as dest:\n",
    "#     dest.write(test_collapse3[np.newaxis])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # current objective: plot the new map over the geo maps to see if they make sense\n",
    "# fig, ax = plt.subplots()\n",
    "# show(test_collapse4,ax=ax,cmap='GnBu')\n",
    "# buurten.plot(ax=ax,\n",
    "#              **{'alpha':0.6,\n",
    "#                      'edgecolor':'w',\n",
    "#                      'facecolor':'lime'\n",
    "#                      })\n",
    "# plt.axis('off')\n",
    "# # fig.savefig('data/test_map.jpg',dpi=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CUT OUT ONLY RDAM SECTOR AND SAVE\n",
    "# rdam_map,rdam_transform = rasterio.mask.mask(nl_map, rdam_geometries,crop=True)\n",
    "rdam_floodmap, rdam_floodtransform = rasterio.mask.mask(flood_map, buurt_geometries, crop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create container of cut flood maps per wijk, per flood map.\n",
    "\n",
    "# need to create labels (lowercase, spaces converted to hyphen)\n",
    "wijk_names = wijken.WK_NAAM.str.replace(' ', '-').str.lower()\n",
    "wijk_geometries = wijken.geometry\n",
    "\n",
    "# create masks for unflooded and flooded tiles\n",
    "\n",
    "wijk_scenario_labels = []\n",
    "# baseline_submaps = []\n",
    "flood_submaps = []\n",
    "\n",
    "# knockout the flood maps with area geo outline\n",
    "for idx, wijk in enumerate(wijk_names):\n",
    "    geo = wijk_geometries[idx]\n",
    "    wijk_scenario_labels.extend([(wijk, number+1) for number, _ in enumerate(flood_maps)])\n",
    "    flood_submaps.extend([rasterio.mask.mask(f_m, [geo], crop=True, nodata=np.nan) for f_m in flood_maps])\n",
    "\n",
    "# put together the items into nice dict\n",
    "# for idx, label in enumerate(wijk_scenario_labels):\n",
    "# extracc\n",
    "w_names, w_scenarios = zip(*wijk_scenario_labels)\n",
    "w_submaps, w_submap_trans = zip(*flood_submaps)\n",
    "w_indices = ['.'.join([str(number), wijk]) for wijk, number in wijk_scenario_labels]\n",
    "\n",
    "# create dict for column form, and then create dataframe\n",
    "df_flood_submaps = pd.DataFrame.from_dict(\n",
    "    {'index': w_indices,\n",
    "      'wijk': w_names,\n",
    "      'scenario': w_scenarios,\n",
    "      'submap': w_submaps,\n",
    "      'transform': w_submap_trans}, orient='columns').set_index('index')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COMPRESS FLOOD SUBMAPS TO PICKLE\n",
    "df_flood_submaps.to_pickle('data/df_flood_submaps.pkl.gz')\n",
    "wijk_names.to_pickle('data/wijk_names.pkl.gz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Infer water to non-water tiles\n",
    "\n",
    "# create masks for different wijks:\n",
    "# wijk_raw_masks = [rasterio.mask.mask(rdam_dsm_map, [w], crop=True, nodata=np.nan) for w in wijk_geometries]\n",
    "\n",
    "# correct flood maps with inland bodies of water\n",
    "dict_wijk_landmasks = dict(zip(\n",
    "    wijk_names,\n",
    "    [rasterio.mask.mask(rdam_land_bool_map, [g], crop=True, nodata=0) for g in wijk_geometries]\n",
    "))\n",
    "# includes np.ndarray and affine transform object\n",
    "\n",
    "# NOTE: 0 set for non-land values, including water and out-of-bounds territory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# assign identification to land area maps\n",
    "# retrieve name for land knockout, use submap\n",
    "# (assumption that the submap is compatible with the transform)\n",
    "# check if all submaps match the landmask (sanity check)\n",
    "\n",
    "# look at column\n",
    "# check shape match\n",
    "# update floodmap item\n",
    "# test_submap = df_flood_submaps.loc['2.delfshaven','submap'].squeeze()\n",
    "# test_landmask = dict_wijk_landmasks['delfshaven'][0].squeeze().astype(bool) # force conversion to bool needed\n",
    "\n",
    "\n",
    "# using np.where preserves the 2d order instead of a bool mask\n",
    "# test_output = np.where(test_landmask, test_submap, test_submap.min())\n",
    "\n",
    "# iterate over rows\n",
    "# use the name of the area for retrieval input to dict_wijk_landmasks\n",
    "# use numpy vectorize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the distribution of flooded and non-flooded tiles per area\n",
    "col_pct_flood = []\n",
    "col_depth_distribution = []\n",
    "col_flood_tiles = []\n",
    "col_land_tiles = []\n",
    "col_new_submaps = []\n",
    "for submap_idx in df_flood_submaps.index:\n",
    "    submap = df_flood_submaps.loc[submap_idx,'submap'].squeeze()\n",
    "    landmask = dict_wijk_landmasks[df_flood_submaps.loc[submap_idx,'wijk']][0].squeeze().astype(bool)\n",
    "    corrected_submap = np.where(landmask, submap, submap.min())\n",
    "    # total area in arbitrary units\n",
    "    land_count = landmask.sum()\n",
    "    flood_distr = corrected_submap[corrected_submap > -9999.]\n",
    "    flood_count = (corrected_submap > -9999.).sum()\n",
    "    # print(land_count,flood_count)\n",
    "    col_depth_distribution.append(flood_distr)\n",
    "    col_pct_flood.append(flood_count/land_count)\n",
    "    col_land_tiles.append(land_count)\n",
    "    col_flood_tiles.append(flood_count)\n",
    "    col_new_submaps.append(corrected_submap)\n",
    "\n",
    "#\n",
    "df_flood_submaps['land_tiles'] = col_land_tiles\n",
    "df_flood_submaps['flood_tiles'] = col_flood_tiles\n",
    "df_flood_submaps['flood_depths'] = col_depth_distribution\n",
    "df_flood_submaps['flood_pct_landmass'] = col_pct_flood\n",
    "df_flood_submaps.submap = col_new_submaps\n",
    "# Assign number of tiles without flood to a new column\n",
    "df_flood_submaps['safe_tiles'] = df_flood_submaps.land_tiles - df_flood_submaps.flood_tiles\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This section focuses on the binning of the flood distribution data for the flood scenarios, per area (wijk/buurt).\n",
    "\n",
    "# digitise to bins of 0.5\n",
    "bins_resolution = 0.5   # metres\n",
    "bins_max = 5   # in metres, but cutoff point is specified to be 5 m (from alessandro's code)\n",
    "bins_total = np.arange(bins_resolution, bins_max + bins_resolution, bins_resolution)\n",
    "\n",
    "flood_distributions_binned = []\n",
    "# use the util function from util_func.py\n",
    "debug_print = False\n",
    "for idx, row in df_flood_submaps.iterrows():\n",
    "    depth_arr = row.flood_depths\n",
    "    binned, outliers, eliminated =  generate_flood_distribution_in_bins(input_arr=depth_arr,\n",
    "                                                  bins=bins_total,outlier_ceil=8.,exclude_outliers=False)\n",
    "    # the exclude_outliers arg was included because some low-lying areas have quite severe flooding, but within 'reasonable' ranges (see Rozenburg scenario 4)\n",
    "    # print wijk and scenario for outliers\n",
    "    print('outliers (acceptable) / outliers (eliminated) / flood / total:') if idx == 0 else None\n",
    "    if len(outliers) > 0 and debug_print:\n",
    "        print(f' {len(outliers)} / {len(eliminated)} / {len(depth_arr)} / {row.land_tiles} ({row.wijk}, {row.scenario})')\n",
    "    # insert extra no-flood bin at the front!\n",
    "    binned = np.insert(binned,0,row.safe_tiles)\n",
    "    # write to list first, assign to df later\n",
    "    flood_distributions_binned.append(binned)\n",
    "\n",
    "# Assign binned distributions to dataframe\n",
    "df_flood_submaps['flood_distribution_bins'] = flood_distributions_binned\n",
    "\n",
    "\n",
    "# what's next? need to convert that into function\n",
    "# need to merge together the flood parts and non-flood parts\n",
    "# could include that in a nice input for np.choice\n",
    "# maybe an overarching function for the maximum bins?\n",
    "# need to get the remainder of non-flooded tiles for generation\n",
    "# need to create agent flood exposure generator, scaled with number of agents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##  want to plot the distribution of flood effects\n",
    "# test with one scenario?\n",
    "subset = df_flood_submaps[df_flood_submaps.scenario == 4]\n",
    "# convert flood depths into long table\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, row in subset.iterrows():\n",
    "    depths = row.loc['flood_depths']\n",
    "    # print(name, max(depths), min(depths))\n",
    "    sns.kdeplot(data=row, x=depths, ax=ax, clip=(0,10))\n",
    "fig.savefig('data_model_inputs/kde_s2_rdam.jpg',dpi=1000)\n",
    "# from the graph, most flooding occur before 4m high for scenario 2\n",
    "# number of houses must match the number of spaces...? Does not account for highrise/high-density housing...\n",
    "\n",
    "# how to generate which houses are damaged?\n",
    "# call all houses to apply floods and damages (latter could be precalculated?)\n",
    "# use dict ledger to keep track of damaages\n",
    "# houses are fixed the next step? but history of flooding remains? Households take up a certain debt to repair? Perhaps no inclusion of repairing yet\n",
    "# logic of house value degradation though\n",
    "# artificial ceiling to 6/7 m since the limit is also as such?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate the zeroth scenario and shift the scenario mode\n",
    "# NOTE: many things are hardcoded here!\n",
    "\n",
    "z_areas = df_flood_submaps.wijk.unique()\n",
    "z_new_rows: dict = {}\n",
    "z_dict_submaps: dict = dict_wijk_landmasks.copy()\n",
    "\n",
    "for key, tup in z_dict_submaps.items():\n",
    "    z_submap, z_transform = tup # split them up again\n",
    "    z_land_tiles = z_submap.sum()\n",
    "    z_submap = np.where(z_submap.astype(bool),0, np.nan).astype('float32') # ensure that cast to the same dtype as the others, but\n",
    "    # insert into index dict\n",
    "    z_new_rows[f\"0.{key}\"] = [key,0, z_submap, z_transform, z_land_tiles, 0, [], 0., z_land_tiles, [z_land_tiles] + [0,0,0,0,0,0,0,0,0]]\n",
    "\n",
    "# convert into pd.Dataframe\n",
    "z_df = pd.DataFrame.from_dict(z_new_rows, orient='index', columns=df_flood_submaps.columns)\n",
    "\n",
    "z_reference = df_flood_submaps[df_flood_submaps.scenario == 3].copy()\n",
    "\n",
    "# sanity check: check the number of land tiles\n",
    "print(f\"sanity check if original land tiles are the same with the df_flood_submaps: {z_df.land_tiles.to_list() == z_reference.land_tiles.to_list()}\")\n",
    "# need to cast the columns into the same dtype\n",
    "for k, v in list(zip(df_flood_submaps.columns, df_flood_submaps.dtypes)):\n",
    "    z_df[k] = z_df[k].astype(v)\n",
    "# concatenate into df_flood_submaps\n",
    "df_flood_submaps = pd.concat([df_flood_submaps, z_df], axis=0).sort_index()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the df into pickle\n",
    "overwrite = False\n",
    "if overwrite:\n",
    "    df_flood_submaps.to_pickle('data_model_inputs/flood_scenarios_per_wijk.pickletable')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}